{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 6: Universal Document Parser\n",
    "\n",
    "This notebook tests the UniversalParser class, which implements a context-aware hierarchical extraction strategy.\n",
    "\n",
    "**Goals:**\n",
    "1. Extract document structure as a hierarchical JSON tree.\n",
    "2. Preserve table structures as data grids.\n",
    "3. Extract and save images/charts as separate files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q google-cloud-documentai python-dotenv pdf2image Pillow\n",
    "print(\"Dependencies installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repository if running in Colab to get utils\n",
    "import os\n",
    "if not os.path.exists('utils'):\n",
    "    !git clone https://github.com/abhii-01/docai-extraction-test.git temp_repo\n",
    "    !mv temp_repo/* .\n",
    "    !rm -rf temp_repo\n",
    "    print(\"Repository cloned.\")\n",
    "else:\n",
    "    print(\"Utils already present.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Credentials\n",
    "from google.colab import files\n",
    "import json\n",
    "\n",
    "if not os.path.exists('docai-credentials.json'):\n",
    "    print(\"Upload your Google Cloud credentials JSON file...\")\n",
    "    uploaded = files.upload()\n",
    "    creds_filename = list(uploaded.keys())[0]\n",
    "    with open('docai-credentials.json', 'wb') as f:\n",
    "        f.write(uploaded[creds_filename])\n",
    "    print(\"Credentials saved.\")\n",
    "else:\n",
    "    print(\"Credentials found.\")\n",
    "\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'docai-credentials.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "DOCAI_PROJECT_ID = \"your-project-id\" # UPDATE THIS\n",
    "DOCAI_PROCESSOR_ID = \"your-layout-parser-id\" # UPDATE THIS\n",
    "DOCAI_LOCATION = \"us\"\n",
    "\n",
    "os.environ['DOCAI_PROJECT_ID'] = DOCAI_PROJECT_ID\n",
    "os.environ['DOCAI_PROCESSOR_ID'] = DOCAI_PROCESSOR_ID\n",
    "os.environ['DOCAI_LOCATION'] = DOCAI_LOCATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.docai_client import get_client_from_env\n",
    "from utils.universal_parser import UniversalParser\n",
    "\n",
    "try:\n",
    "    client = get_client_from_env()\n",
    "    parser = UniversalParser(client, output_dir=\"universal_output\")\n",
    "    print(\"UniversalParser initialized successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Upload and Parse PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Upload a PDF file to test (preferably one with headings, tables, and images)...\")\n",
    "uploaded = files.upload()\n",
    "pdf_filename = list(uploaded.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the parser\n",
    "result = parser.parse(pdf_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Explore Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "print(f\"Processing Complete.\")\n",
    "print(f\"Metadata: {result['metadata']}\")\n",
    "print(f\"Top-level blocks found: {len(result['structure'])}\")\n",
    "\n",
    "# Function to print tree summary\n",
    "def print_tree(nodes, level=0):\n",
    "    for node in nodes:\n",
    "        indent = \"  \" * level\n",
    "        info = f\"{indent}- [{node['type']}] (ID: {node['id']})\"\n",
    "        if node.get('text'):\n",
    "            preview = node['text'][:50].replace('\\n', ' ') + \"...\"\n",
    "            info += f\" : {preview}\"\n",
    "        if node.get('file_path'):\n",
    "            info += f\" [Saved Image: {node['file_path']}]\"\n",
    "        if node.get('type') == 'table':\n",
    "            rows = len(node.get('data', {}).get('simple_matrix', []))\n",
    "            info += f\" [Table: {rows} rows]\"\n",
    "        print(info)\n",
    "        if node.get('children'):\n",
    "            print_tree(node['children'], level + 1)\n",
    "\n",
    "print(\"\\n--- Document Structure ---\")\n",
    "print_tree(result['structure'][:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. View Extracted Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper to find tables recursively\n",
    "def find_tables(nodes):\n",
    "    tables = []\n",
    "    for node in nodes:\n",
    "        if node['type'] == 'table':\n",
    "            tables.append(node)\n",
    "        if node.get('children'):\n",
    "            tables.extend(find_tables(node['children']))\n",
    "    return tables\n",
    "\n",
    "tables = find_tables(result['structure'])\n",
    "print(f\"Found {len(tables)} tables.\")\n",
    "\n",
    "for i, table in enumerate(tables):\n",
    "    print(f\"\\nTable {i+1}:\")\n",
    "    matrix = table['data']['simple_matrix']\n",
    "    for row in matrix:\n",
    "        print(f\"  {row}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. View Extracted Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "def find_images(nodes):\n",
    "    imgs = []\n",
    "    for node in nodes:\n",
    "        if node.get('file_path'):\n",
    "            imgs.append(node)\n",
    "        if node.get('children'):\n",
    "            imgs.extend(find_images(node['children']))\n",
    "    return imgs\n",
    "\n",
    "extracted_images = find_images(result['structure'])\n",
    "print(f\"Found {len(extracted_images)} images.\")\n",
    "\n",
    "for img in extracted_images:\n",
    "    print(f\"\\n[{img['type']}] {img['file_path']}\")\n",
    "    try:\n",
    "        display(Image(filename=img['file_path']))\n",
    "    except Exception as e:\n",
    "        print(f\"Could not display image: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Full JSON Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = \"universal_parsed_result.json\"\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(result, f, indent=2)\n",
    "\n",
    "print(f\"Full JSON saved to {output_file}\")\n",
    "files.download(output_file)\n",
    "\n",
    "# Also zip and download images if any\n",
    "if extracted_images:\n",
    "    !zip -r extracted_images.zip universal_output/images\n",
    "    files.download('extracted_images.zip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test 1: Basic Text Extraction with Layout Parser\n",
        "\n",
        "**Goal:** Verify Google Document AI Layout Parser works and extracts raw text from PDFs\n",
        "\n",
        "**What this test does:**\n",
        "- Connects to Google Document AI with Layout Parser processor\n",
        "- Processes a PDF document\n",
        "- Extracts text using `document_layout.blocks` (Layout Parser API)\n",
        "- Saves results to JSON file\n",
        "\n",
        "**Layout Parser API (Dec 2025):**\n",
        "- Returns data in `document.document_layout.blocks` (NOT `document.pages`)\n",
        "- Each block contains `text_block.text` and `text_block.type_`\n",
        "- Block types: paragraph, heading, list_item, table, etc.\n",
        "- Superior structure detection for academic documents\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Install Dependencies\n",
        "\n",
        "Run this cell to install required packages for Google Colab.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with '.venv (Python 3.13.7)' requires the ipykernel package.\n",
            "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '/Users/aadarsh/Documents/code/docai-test/.venv/bin/python -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "%pip install -q google-cloud-documentai python-dotenv openai anthropic pdf2image Pillow\n",
        "print(\"âœ… All dependencies installed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Upload Credentials\n",
        "\n",
        "Upload your Google Cloud service account JSON file.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import json\n",
        "import os\n",
        "\n",
        "print(\"ðŸ“¤ Please upload your Google Cloud credentials JSON file...\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Save credentials\n",
        "creds_filename = list(uploaded.keys())[0]\n",
        "credentials_content = json.loads(uploaded[creds_filename].decode('utf-8'))\n",
        "\n",
        "# Write to temporary file\n",
        "with open('docai-credentials.json', 'w') as f:\n",
        "    json.dump(credentials_content, f)\n",
        "\n",
        "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'docai-credentials.json'\n",
        "print(f\"âœ… Credentials saved: {creds_filename}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Configure Environment\n",
        "\n",
        "Set your Google Cloud project ID and Layout Parser processor ID.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration - UPDATE THESE VALUES\n",
        "DOCAI_PROJECT_ID = \"your-project-id-here\"  # Replace with your project ID\n",
        "DOCAI_PROCESSOR_ID = \"your-processor-id-here\"  # Replace with your Layout Parser processor ID\n",
        "DOCAI_LOCATION = \"us\"  # us, eu, or asia\n",
        "\n",
        "# Set environment variables\n",
        "os.environ['DOCAI_PROJECT_ID'] = DOCAI_PROJECT_ID\n",
        "os.environ['DOCAI_PROCESSOR_ID'] = DOCAI_PROCESSOR_ID\n",
        "os.environ['DOCAI_LOCATION'] = DOCAI_LOCATION\n",
        "\n",
        "print(f\"âœ… Configuration set:\")\n",
        "print(f\"   Project: {DOCAI_PROJECT_ID}\")\n",
        "print(f\"   Processor: {DOCAI_PROCESSOR_ID}\")\n",
        "print(f\"   Location: {DOCAI_LOCATION}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Initialize Document AI Client\n",
        "\n",
        "Set up the Document AI client for Layout Parser.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize Document AI client directly (Layout Parser API - Dec 2025)\n",
        "from google.cloud import documentai_v1 as documentai\n",
        "\n",
        "# Build processor name\n",
        "processor_name = f\"projects/{DOCAI_PROJECT_ID}/locations/{DOCAI_LOCATION}/processors/{DOCAI_PROCESSOR_ID}\"\n",
        "\n",
        "# Create client\n",
        "client = documentai.DocumentProcessorServiceClient()\n",
        "\n",
        "print(f\"âœ… Document AI client initialized\")\n",
        "print(f\"   Processor: {processor_name}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Verify Setup\n",
        "\n",
        "Test connection to Google Document AI.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"ðŸ” Verifying Document AI setup...\\n\")\n",
        "\n",
        "try:\n",
        "    # Get processor info to verify it exists and is enabled\n",
        "    processor = client.get_processor(name=processor_name)\n",
        "    \n",
        "    print(f\"âœ… Processor found!\")\n",
        "    print(f\"   Name: {processor.display_name}\")\n",
        "    print(f\"   Type: {processor.type_}\")\n",
        "    print(f\"   State: {documentai.Processor.State(processor.state).name}\")\n",
        "    \n",
        "    if processor.state == documentai.Processor.State.ENABLED:\n",
        "        print(\"\\nâœ… Setup verified! Ready to process documents.\")\n",
        "    else:\n",
        "        print(f\"\\nâš ï¸ Processor state is {documentai.Processor.State(processor.state).name}\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"\\nâŒ Setup verification failed: {e}\")\n",
        "    print(\"\\nPlease check:\")\n",
        "    print(\"  1. Credentials file is valid\")\n",
        "    print(\"  2. Project ID is correct\")\n",
        "    print(\"  3. Processor ID is correct\")\n",
        "    print(\"  4. Layout Parser processor exists and is enabled\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Upload PDF for Testing\n",
        "\n",
        "Upload your PDF file to process.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"ðŸ“¤ Please upload your PDF file...\")\n",
        "uploaded_pdfs = files.upload()\n",
        "\n",
        "# Get the first uploaded PDF\n",
        "pdf_filename = list(uploaded_pdfs.keys())[0]\n",
        "pdf_path = pdf_filename\n",
        "\n",
        "print(f\"âœ… PDF uploaded: {pdf_filename}\")\n",
        "print(f\"   Size: {len(uploaded_pdfs[pdf_filename]) / 1024:.1f} KB\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Process Document with Layout Parser\n",
        "\n",
        "Extract text from the PDF using Layout Parser processor.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"{'='*60}\")\n",
        "print(\"TEST 1: BASIC TEXT EXTRACTION (Layout Parser API)\")\n",
        "print(f\"{'='*60}\\n\")\n",
        "\n",
        "# Read PDF content\n",
        "with open(pdf_path, 'rb') as f:\n",
        "    pdf_content = f.read()\n",
        "\n",
        "print(f\"ðŸ“„ Processing PDF with Layout Parser: {pdf_path}\")\n",
        "print(f\"   File size: {len(pdf_content):,} bytes\")\n",
        "\n",
        "# Create process request\n",
        "request = documentai.ProcessRequest(\n",
        "    name=processor_name,\n",
        "    raw_document=documentai.RawDocument(\n",
        "        content=pdf_content,\n",
        "        mime_type=\"application/pdf\"\n",
        "    ),\n",
        "    skip_human_review=True\n",
        ")\n",
        "\n",
        "# Process document\n",
        "result = client.process_document(request=request)\n",
        "document = result.document\n",
        "\n",
        "# Layout Parser returns data in document_layout.blocks (NOT document.pages/text)\n",
        "doc_layout = document.document_layout\n",
        "\n",
        "# Extract all text from blocks\n",
        "full_text = \"\"\n",
        "total_blocks = 0\n",
        "\n",
        "if doc_layout and doc_layout.blocks:\n",
        "    total_blocks = len(doc_layout.blocks)\n",
        "    for block in doc_layout.blocks:\n",
        "        if block.text_block and block.text_block.text:\n",
        "            full_text += block.text_block.text + \"\\n\"\n",
        "\n",
        "print(f\"âœ… Document processed successfully!\")\n",
        "print(f\"   Total blocks: {total_blocks}\")\n",
        "print(f\"   Total characters: {len(full_text):,}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Extract Blocks by Type\n",
        "\n",
        "Extract text blocks organized by type (paragraph, heading, list, table, etc.).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"ðŸ“ Extracting blocks by type...\\n\")\n",
        "\n",
        "blocks_data = []\n",
        "block_types = {}\n",
        "\n",
        "if doc_layout and doc_layout.blocks:\n",
        "    for block in doc_layout.blocks:\n",
        "        block_info = {\n",
        "            \"block_id\": block.block_id,\n",
        "            \"type\": None,\n",
        "            \"text\": None,\n",
        "            \"page_start\": None,\n",
        "            \"page_end\": None\n",
        "        }\n",
        "        \n",
        "        # Get text block info\n",
        "        if block.text_block:\n",
        "            block_info[\"type\"] = str(block.text_block.type_) if block.text_block.type_ else \"unknown\"\n",
        "            block_info[\"text\"] = block.text_block.text if block.text_block.text else \"\"\n",
        "            \n",
        "            # Count block types\n",
        "            block_type = block_info[\"type\"]\n",
        "            block_types[block_type] = block_types.get(block_type, 0) + 1\n",
        "        \n",
        "        # Get page span\n",
        "        if block.page_span:\n",
        "            block_info[\"page_start\"] = block.page_span.page_start\n",
        "            block_info[\"page_end\"] = block.page_span.page_end\n",
        "        \n",
        "        blocks_data.append(block_info)\n",
        "\n",
        "# Print summary\n",
        "print(f\"ðŸ“Š Block Types Found:\")\n",
        "for block_type, count in sorted(block_types.items()):\n",
        "    print(f\"   {block_type}: {count}\")\n",
        "\n",
        "print(f\"\\nâœ… Extracted {len(blocks_data)} blocks\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 9: Preview Extracted Text\n",
        "\n",
        "Display a preview of the extracted text.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"ðŸ“„ TEXT PREVIEW (first 800 characters):\")\n",
        "print(\"=\" * 60)\n",
        "print(full_text[:800])\n",
        "if len(full_text) > 800:\n",
        "    print(\"...\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 10: Save Results to JSON\n",
        "\n",
        "Save extraction results to a JSON file.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "# Build results\n",
        "results = {\n",
        "    \"pdf_file\": Path(pdf_path).name,\n",
        "    \"total_blocks\": len(blocks_data),\n",
        "    \"total_characters\": len(full_text),\n",
        "    \"block_type_counts\": block_types,\n",
        "    \"full_text\": full_text,\n",
        "    \"blocks\": blocks_data\n",
        "}\n",
        "\n",
        "# Save to JSON\n",
        "output_path = \"test1_raw_text.json\"\n",
        "with open(output_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(results, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "print(f\"ðŸ’¾ Results saved to: {output_path}\")\n",
        "print(f\"\\nðŸ“Š Summary:\")\n",
        "print(f\"  Total blocks: {len(blocks_data)}\")\n",
        "print(f\"  Total characters: {len(full_text):,}\")\n",
        "print(f\"  Block types: {block_types}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 11: Download Results\n",
        "\n",
        "Download the JSON results file to your computer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "print(\"ðŸ“¥ Downloading results...\")\n",
        "files.download(output_path)\n",
        "print(f\"âœ… Test 1 complete! Results downloaded.\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}

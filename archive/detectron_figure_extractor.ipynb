{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Detectron2 Figure Extractor\n",
        "\n",
        "**Purpose:** Detect and extract figures from PDFs using Detectron2 + LayoutParser.\n",
        "\n",
        "**Python:** 3.10 (Colab default)\n",
        "\n",
        "**Flow:** PDF ‚Üí Render pages ‚Üí Detectron2 figure detection ‚Üí Crop ‚Üí GPT-4o Vision descriptions\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 1: Install Dependencies\n",
        "\n",
        "‚ö†Ô∏è **This cell takes ~3-5 minutes** (Detectron2 compilation)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# System dependencies\n",
        "!apt-get update -qq && apt-get install -y -qq poppler-utils\n",
        "\n",
        "# Python packages\n",
        "%pip install -q pdf2image Pillow openai\n",
        "\n",
        "# PyTorch (Colab usually has it, ensure CUDA 11.8 version)\n",
        "%pip install -q torch torchvision --index-url https://download.pytorch.org/whl/cu118\n",
        "\n",
        "# Detectron2 from source\n",
        "!python -m pip install -q 'git+https://github.com/facebookresearch/detectron2.git'\n",
        "\n",
        "# LayoutParser with Detectron2 support\n",
        "%pip install -q \"layoutparser[layoutmodels]\"\n",
        "\n",
        "print(\"‚úÖ Dependencies installed - restart runtime if prompted\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 2: Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# === CONFIGURATION ===\n",
        "OPENAI_API_KEY = \"\"  # Set your key here or use env var\n",
        "PDF_PATH = \"sample.pdf\"  # Will be set after upload\n",
        "OUTPUT_DIR = \"detectron_output\"\n",
        "RENDER_DPI = 150  # Higher = better quality but slower\n",
        "\n",
        "# Set API key\n",
        "if OPENAI_API_KEY:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
        "\n",
        "# Create output directory\n",
        "output_path = Path(OUTPUT_DIR)\n",
        "output_path.mkdir(exist_ok=True)\n",
        "(output_path / \"figures\").mkdir(exist_ok=True)\n",
        "\n",
        "print(f\"üìÅ Output directory: {output_path.absolute()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 3: Upload PDF (Colab)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "print(\"üì§ Upload your PDF:\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "if uploaded:\n",
        "    PDF_PATH = list(uploaded.keys())[0]\n",
        "    print(f\"‚úÖ Using: {PDF_PATH}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No file uploaded\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 4: Initialize Detectron2 Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from layoutparser.models import Detectron2LayoutModel\n",
        "\n",
        "# Load PubLayNet model (trained on academic papers)\n",
        "# Labels: Text, Title, List, Table, Figure\n",
        "print(\"üîÑ Loading Detectron2 model (first run downloads ~350MB)...\")\n",
        "\n",
        "model = Detectron2LayoutModel(\n",
        "    config_path=\"lp://PubLayNet/faster_rcnn_R_50_FPN_3x/config\",\n",
        "    extra_config=[\"MODEL.ROI_HEADS.SCORE_THRESH_TEST\", 0.5],\n",
        "    label_map={0: \"Text\", 1: \"Title\", 2: \"List\", 3: \"Table\", 4: \"Figure\"}\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Detectron2 model loaded\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 5: Detect & Crop Figures\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pdf2image import convert_from_path\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "def detect_figures(pdf_path: str, model, output_dir: Path, dpi: int = 150):\n",
        "    \"\"\"Detect figures in PDF using Detectron2, crop and save them.\"\"\"\n",
        "    figures = []\n",
        "    figures_dir = output_dir / \"figures\"\n",
        "    \n",
        "    # Render PDF pages\n",
        "    print(f\"üìÑ Rendering PDF at {dpi} DPI...\")\n",
        "    pages = convert_from_path(pdf_path, dpi=dpi)\n",
        "    print(f\"   Found {len(pages)} pages\")\n",
        "    \n",
        "    for page_num, page_img in enumerate(pages, start=1):\n",
        "        print(f\"   Processing page {page_num}...\")\n",
        "        \n",
        "        img_array = np.array(page_img)\n",
        "        width, height = page_img.size\n",
        "        \n",
        "        # Run layout detection\n",
        "        layout = model.detect(img_array)\n",
        "        \n",
        "        # Filter for figures only\n",
        "        figure_blocks = [b for b in layout if b.type == \"Figure\"]\n",
        "        \n",
        "        for idx, block in enumerate(figure_blocks, start=1):\n",
        "            x1 = int(block.block.x_1)\n",
        "            y1 = int(block.block.y_1)\n",
        "            x2 = int(block.block.x_2)\n",
        "            y2 = int(block.block.y_2)\n",
        "            \n",
        "            # Skip tiny detections\n",
        "            area_ratio = ((x2 - x1) * (y2 - y1)) / (width * height)\n",
        "            if area_ratio < 0.01:\n",
        "                continue\n",
        "            \n",
        "            # Crop and save\n",
        "            cropped = page_img.crop((x1, y1, x2, y2))\n",
        "            fig_id = f\"fig_p{page_num:02d}_{idx:02d}\"\n",
        "            file_path = figures_dir / f\"{fig_id}.png\"\n",
        "            cropped.save(file_path, \"PNG\")\n",
        "            \n",
        "            figures.append({\n",
        "                \"id\": fig_id,\n",
        "                \"page\": page_num,\n",
        "                \"bbox\": [x1/width, y1/height, x2/width, y2/height],\n",
        "                \"confidence\": round(block.score, 3),\n",
        "                \"file_path\": str(file_path),\n",
        "                \"description\": None\n",
        "            })\n",
        "            print(f\"      ‚úì {fig_id} (conf: {block.score:.2f})\")\n",
        "    \n",
        "    return figures\n",
        "\n",
        "# Run detection\n",
        "detected_figures = detect_figures(PDF_PATH, model, output_path, dpi=RENDER_DPI)\n",
        "print(f\"\\nüéØ Total figures detected: {len(detected_figures)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 6: GPT-4o Vision Descriptions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "import base64\n",
        "from openai import OpenAI\n",
        "\n",
        "def encode_image_base64(image_path: str) -> str:\n",
        "    with open(image_path, \"rb\") as f:\n",
        "        return base64.b64encode(f.read()).decode(\"utf-8\")\n",
        "\n",
        "def describe_figure(client: OpenAI, image_path: str) -> str:\n",
        "    \"\"\"Get GPT-4o Vision description of a figure.\"\"\"\n",
        "    base64_img = encode_image_base64(image_path)\n",
        "    \n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[{\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\"type\": \"text\", \"text\": \"Describe this figure concisely in 1-2 sentences. Focus on what it shows (chart type, data, diagram elements).\"},\n",
        "                {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{base64_img}\", \"detail\": \"low\"}}\n",
        "            ]\n",
        "        }],\n",
        "        max_tokens=150\n",
        "    )\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "# Generate descriptions\n",
        "if detected_figures and os.environ.get(\"OPENAI_API_KEY\"):\n",
        "    print(\"ü§ñ Generating GPT-4o Vision descriptions...\\n\")\n",
        "    client = OpenAI()\n",
        "    \n",
        "    for fig in detected_figures:\n",
        "        print(f\"   {fig['id']}...\", end=\" \")\n",
        "        try:\n",
        "            fig[\"description\"] = describe_figure(client, fig[\"file_path\"])\n",
        "            print(\"‚úì\")\n",
        "        except Exception as e:\n",
        "            fig[\"description\"] = f\"Error: {e}\"\n",
        "            print(f\"‚úó\")\n",
        "    \n",
        "    print(\"\\n‚úÖ Descriptions complete\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Skipping descriptions (no API key or no figures)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 7: Save Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "# Build output JSON\n",
        "result = {\n",
        "    \"metadata\": {\n",
        "        \"source_file\": PDF_PATH,\n",
        "        \"extraction_method\": \"detectron2_layoutparser\",\n",
        "        \"model\": \"PubLayNet/faster_rcnn_R_50_FPN_3x\",\n",
        "        \"timestamp\": datetime.now().isoformat(),\n",
        "        \"figures_detected\": len(detected_figures)\n",
        "    },\n",
        "    \"figures\": detected_figures\n",
        "}\n",
        "\n",
        "# Save JSON\n",
        "output_json = output_path / \"detectron_figures.json\"\n",
        "with open(output_json, \"w\") as f:\n",
        "    json.dump(result, f, indent=2)\n",
        "\n",
        "print(f\"üíæ Saved: {output_json}\")\n",
        "\n",
        "# Display results\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "for fig in detected_figures:\n",
        "    print(f\"\\nüì∑ {fig['id']} (page {fig['page']}, conf: {fig['confidence']})\")\n",
        "    if fig['description']:\n",
        "        print(f\"   ‚Üí {fig['description'][:100]}...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 8: Download (Colab)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "# Zip and download\n",
        "zip_path = shutil.make_archive(\"detectron_output\", \"zip\", output_path)\n",
        "files.download(zip_path)\n",
        "print(\"‚úÖ Download started\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}

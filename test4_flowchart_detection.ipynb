{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test 4: Flowchart Detection with Layout Parser\n",
        "\n",
        "**Goal:** Detect flowcharts/diagrams and describe them using Vision LLM\n",
        "\n",
        "This notebook tests the flowchart/diagram detection and description capabilities using **Layout Parser** and **Vision LLM**.\n",
        "\n",
        "## What This Test Does:\n",
        "- ‚úÖ Uses Layout Parser to detect images in PDFs\n",
        "- ‚úÖ Filters for likely diagrams/flowcharts (vs photos)\n",
        "- ‚úÖ Extracts image regions from PDF pages\n",
        "- ‚úÖ Uses Vision LLM (GPT-4 Vision or Claude) to generate descriptions\n",
        "- ‚úÖ Saves descriptions for taxonomy matching\n",
        "\n",
        "**Why This Matters:**\n",
        "- Makes visual content searchable\n",
        "- Creates accessible text versions of diagrams\n",
        "- Essential for comprehensive textbook processing\n",
        "- Layout Parser provides accurate image boundary detection\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Install Dependencies\n",
        "\n",
        "Run this cell to install required packages for Google Colab.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -q google-cloud-documentai python-dotenv openai anthropic pdf2image Pillow\n",
        "print(\"‚úÖ All dependencies installed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Upload Credentials\n",
        "\n",
        "Upload your Google Cloud service account JSON file.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import json\n",
        "import os\n",
        "\n",
        "print(\"üì§ Please upload your Google Cloud credentials JSON file...\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "creds_filename = list(uploaded.keys())[0]\n",
        "credentials_content = json.loads(uploaded[creds_filename].decode('utf-8'))\n",
        "\n",
        "with open('docai-credentials.json', 'w') as f:\n",
        "    json.dump(credentials_content, f)\n",
        "\n",
        "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'docai-credentials.json'\n",
        "print(f\"‚úÖ Credentials saved: {creds_filename}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Configure Environment\n",
        "\n",
        "Set your Google Cloud project ID, Layout Parser processor ID, and Vision LLM API key.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration - UPDATE THESE VALUES\n",
        "DOCAI_PROJECT_ID = \"your-project-id-here\"\n",
        "DOCAI_PROCESSOR_ID = \"your-layout-parser-processor-id\"\n",
        "DOCAI_LOCATION = \"us\"\n",
        "\n",
        "# LLM Configuration for flowchart description\n",
        "OPENAI_API_KEY = \"sk-your-openai-key-here\"  # Or use ANTHROPIC_API_KEY\n",
        "LLM_PROVIDER = \"openai\"  # or \"anthropic\"\n",
        "\n",
        "os.environ['DOCAI_PROJECT_ID'] = DOCAI_PROJECT_ID\n",
        "os.environ['DOCAI_PROCESSOR_ID'] = DOCAI_PROCESSOR_ID\n",
        "os.environ['DOCAI_LOCATION'] = DOCAI_LOCATION\n",
        "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
        "os.environ['LLM_PROVIDER'] = LLM_PROVIDER\n",
        "\n",
        "print(f\"‚úÖ Configuration set:\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Clone Repository and Load Utils\n",
        "\n",
        "Clone the repository to access utility functions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!git clone https://github.com/abhii-01/python-automation.git\n",
        "%cd python-automation\n",
        "\n",
        "import sys\n",
        "from pathlib import Path\n",
        "sys.path.append(str(Path.cwd()))\n",
        "\n",
        "from utils.docai_client import get_client_from_env\n",
        "from utils.vision_llm import describe_image_with_llm, extract_image_from_pdf, is_likely_diagram\n",
        "\n",
        "print(\"‚úÖ Repository cloned and utilities loaded\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Verify Setup\n",
        "\n",
        "Test connection to Google Document AI.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"üîç Verifying Document AI setup...\\n\")\n",
        "\n",
        "try:\n",
        "    client = get_client_from_env()\n",
        "    client.verify_setup()\n",
        "    print(\"\\n‚úÖ Setup verified! Ready to process documents.\")\n",
        "except Exception as e:\n",
        "    print(f\"\\n‚ùå Setup verification failed: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Upload PDF for Testing\n",
        "\n",
        "Upload your PDF file with diagrams/flowcharts to process.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"üì§ Please upload your PDF file (should contain diagrams/flowcharts)...\")\n",
        "uploaded_pdfs = files.upload()\n",
        "\n",
        "pdf_filename = list(uploaded_pdfs.keys())[0]\n",
        "pdf_path = pdf_filename\n",
        "\n",
        "print(f\"‚úÖ PDF uploaded: {pdf_filename}\")\n",
        "print(f\"   Size: {len(uploaded_pdfs[pdf_filename]) / 1024:.1f} KB\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Process Document with Layout Parser\n",
        "\n",
        "Process the PDF to detect images.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"{'='*60}\")\n",
        "print(\"TEST 4: FLOWCHART DETECTION\")\n",
        "print(f\"{'='*60}\\n\")\n",
        "\n",
        "print(f\"üìÑ Processing PDF with Layout Parser: {pdf_path}\")\n",
        "document = client.process_document(pdf_path)\n",
        "\n",
        "print(f\"‚úÖ Document processed!\")\n",
        "print(f\"   Total pages: {len(document.pages)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Define Helper Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_bounding_box(bounding_poly):\n",
        "    \"\"\"Extract normalized bounding box from polygon\"\"\"\n",
        "    if not bounding_poly or not hasattr(bounding_poly, 'normalized_vertices'):\n",
        "        return {\"x_min\": 0, \"y_min\": 0, \"x_max\": 0, \"y_max\": 0}\n",
        "    \n",
        "    vertices = bounding_poly.normalized_vertices\n",
        "    if not vertices:\n",
        "        return {\"x_min\": 0, \"y_min\": 0, \"x_max\": 0, \"y_max\": 0}\n",
        "    \n",
        "    x_coords = [v.x for v in vertices]\n",
        "    y_coords = [v.y for v in vertices]\n",
        "    \n",
        "    return {\n",
        "        \"x_min\": min(x_coords),\n",
        "        \"y_min\": min(y_coords),\n",
        "        \"x_max\": max(x_coords),\n",
        "        \"y_max\": max(y_coords)\n",
        "    }\n",
        "\n",
        "def get_page_text(page, full_text):\n",
        "    \"\"\"Extract text from a page\"\"\"\n",
        "    text_parts = []\n",
        "    for paragraph in page.paragraphs:\n",
        "        if paragraph.layout.text_anchor:\n",
        "            for segment in paragraph.layout.text_anchor.text_segments:\n",
        "                text = full_text[segment.start_index:segment.end_index]\n",
        "                text_parts.append(text)\n",
        "    return \" \".join(text_parts)\n",
        "\n",
        "print(\"‚úÖ Helper functions defined\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 9: Detect and Process Flowcharts/Diagrams\n",
        "\n",
        "Extract images and generate descriptions using Vision LLM.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\nüîç Detecting diagrams and flowcharts...\\n\")\n",
        "\n",
        "diagram_results = []\n",
        "diagram_count = 0\n",
        "\n",
        "for page_num, page in enumerate(document.pages, 1):\n",
        "    # Check for images on this page\n",
        "    if not hasattr(page, 'image') or not page.image:\n",
        "        continue\n",
        "    \n",
        "    print(f\"  Page {page_num}: Found {len(page.image)} image(s)\")\n",
        "    \n",
        "    for img_idx, image in enumerate(page.image):\n",
        "        # Get bounding box\n",
        "        bbox = get_bounding_box(image.layout.bounding_poly)\n",
        "        \n",
        "        # Get page text for context\n",
        "        page_text = get_page_text(page, document.text)\n",
        "        \n",
        "        # Check if likely a diagram\n",
        "        if not is_likely_diagram(bbox, page_text):\n",
        "            print(f\"    Image {img_idx + 1}: Skipped (likely photo/decoration)\")\n",
        "            continue\n",
        "        \n",
        "        diagram_count += 1\n",
        "        print(f\"    Image {img_idx + 1}: Detected as diagram\")\n",
        "        \n",
        "        # Extract image region from PDF\n",
        "        print(f\"      Extracting image region...\")\n",
        "        try:\n",
        "            image_bytes = extract_image_from_pdf(pdf_path, page_num - 1, bbox)\n",
        "            print(f\"      ‚úÖ Extracted ({len(image_bytes)} bytes)\")\n",
        "        except Exception as e:\n",
        "            print(f\"      ‚ö†Ô∏è  Extraction failed: {e}\")\n",
        "            continue\n",
        "        \n",
        "        # Describe with Vision LLM\n",
        "        print(f\"      ü§ñ Generating description with Vision LLM...\")\n",
        "        try:\n",
        "            description = describe_image_with_llm(\n",
        "                image_bytes,\n",
        "                image_type=\"flowchart\"\n",
        "            )\n",
        "            print(f\"      ‚úÖ Description generated ({len(description)} chars)\")\n",
        "        except Exception as e:\n",
        "            print(f\"      ‚ö†Ô∏è  LLM description failed: {e}\")\n",
        "            description = f\"[Description generation failed: {e}]\"\n",
        "        \n",
        "        # Store result\n",
        "        result = {\n",
        "            \"diagram_id\": f\"diagram_{diagram_count}\",\n",
        "            \"page\": page_num,\n",
        "            \"image_index\": img_idx,\n",
        "            \"bbox\": bbox,\n",
        "            \"area_percentage\": (bbox['x_max'] - bbox['x_min']) * (bbox['y_max'] - bbox['y_min']) * 100,\n",
        "            \"description\": description\n",
        "        }\n",
        "        \n",
        "        diagram_results.append(result)\n",
        "\n",
        "print(f\"\\n‚úÖ Processed {diagram_count} diagrams\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 10: View Results\n",
        "\n",
        "Display detected diagrams and their descriptions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"{'='*60}\")\n",
        "print(\"‚úÖ FLOWCHART DETECTION COMPLETE\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"üìä Summary:\")\n",
        "print(f\"  Total diagrams found: {diagram_count}\")\n",
        "print(f\"  Successfully described: {len(diagram_results)}\")\n",
        "\n",
        "if diagram_results:\n",
        "    print(f\"\\nüìù Example description (Diagram 1):\")\n",
        "    print(\"-\" * 60)\n",
        "    example_desc = diagram_results[0]['description']\n",
        "    print(example_desc[:400])\n",
        "    if len(example_desc) > 400:\n",
        "        print(\"...\")\n",
        "    print(\"-\" * 60)\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è  No diagrams found in this document\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 11: Save Results to JSON\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "results = {\n",
        "    \"pdf_file\": Path(pdf_path).name,\n",
        "    \"total_diagrams\": diagram_count,\n",
        "    \"diagrams\": diagram_results\n",
        "}\n",
        "\n",
        "output_path = \"test4_flowcharts.json\"\n",
        "with open(output_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(results, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "print(f\"\\nüíæ Results saved to: {output_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 12: Download Results\n",
        "\n",
        "Download the JSON results file to your computer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "files.download(output_path)\n",
        "print(f\"‚úÖ Test 4 complete! Results downloaded.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}

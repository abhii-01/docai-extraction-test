{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Image Extractor - Standalone Pipeline\n",
        "\n",
        "Extract images, charts, and diagrams from PDFs using **precise detection** + Vision LLM descriptions.\n",
        "\n",
        "**Features:**\n",
        "- **PyMuPDF**: Extracts embedded images with exact boundaries (FREE)\n",
        "- **LayoutParser**: Detects figure/chart regions that aren't embedded images (FREE)\n",
        "- **GPT-4o Vision**: Describes extracted images only (cost-efficient)\n",
        "- Outputs `image_extractions.json`\n",
        "\n",
        "**No Google Doc AI dependencies. Precise bounding boxes. Minimal LLM cost.**\n",
        "\n",
        "---\n",
        "\n",
        "## How It Works\n",
        "\n",
        "1. **PyMuPDF**: Extract all embedded images (photos, scans) with exact coordinates\n",
        "2. **LayoutParser**: Detect \"Figure\" regions on rendered pages (vector charts, infographics)\n",
        "3. **Combine**: Merge both sources, deduplicate overlapping regions\n",
        "4. **Describe**: Send ONLY extracted images to GPT-4o (not full pages)\n",
        "5. **Output**: Save JSON with image metadata + descriptions\n",
        "\n",
        "---\n",
        "\n",
        "## Cost Comparison\n",
        "\n",
        "| Approach | What Goes to LLM | Cost (10-page PDF) |\n",
        "|----------|-----------------|-------------------|\n",
        "| Old (full page) | Every page | ~$0.30 |\n",
        "| New (images only) | Only 5 images | ~$0.05 |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Install Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install Python packages\n",
        "%pip install -q pdf2image Pillow openai PyMuPDF\n",
        "\n",
        "# Install LayoutParser with detection models\n",
        "%pip install -q layoutparser\n",
        "%pip install -q 'layoutparser[layoutmodels]' torch torchvision\n",
        "\n",
        "# Install Poppler (required by pdf2image to render PDFs)\n",
        "!apt-get update -qq && apt-get install -y -qq poppler-utils\n",
        "\n",
        "print(\"âœ… Dependencies installed successfully!\")\n",
        "print(\"   - PyMuPDF: Extract embedded images\")\n",
        "print(\"   - LayoutParser: Detect figure regions\")\n",
        "print(\"   - OpenAI: Image descriptions\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# ============================================================\n",
        "# CONFIGURATION - Update these values\n",
        "# ============================================================\n",
        "\n",
        "# OpenAI API Key (for Vision LLM)\n",
        "OPENAI_API_KEY = \"\"  # Paste your key here, or set via environment\n",
        "\n",
        "# Output directory for extracted images\n",
        "OUTPUT_DIR = \"image_output\"\n",
        "\n",
        "# ============================================================\n",
        "# Set environment variable\n",
        "if OPENAI_API_KEY:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
        "elif not os.getenv(\"OPENAI_API_KEY\"):\n",
        "    print(\"âš ï¸ Warning: OPENAI_API_KEY not set. Please set it above or via environment.\")\n",
        "\n",
        "# Create output directories\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "os.makedirs(os.path.join(OUTPUT_DIR, \"images\"), exist_ok=True)\n",
        "\n",
        "print(f\"âœ… Output directory: {OUTPUT_DIR}/\")\n",
        "print(f\"âœ… Images will be saved to: {OUTPUT_DIR}/images/\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Upload PDF\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "print(\"Upload a PDF file to extract images from...\")\n",
        "uploaded = files.upload()\n",
        "pdf_filename = list(uploaded.keys())[0]\n",
        "print(f\"âœ… Uploaded: {pdf_filename}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Image Extractor Class\n",
        "\n",
        "**Hybrid detection pipeline:**\n",
        "1. PyMuPDF â†’ Extracts embedded images (exact boundaries)\n",
        "2. LayoutParser â†’ Detects figure regions (vector charts, infographics)\n",
        "3. GPT-4o â†’ Describes each extracted image (cost-efficient)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import base64\n",
        "from typing import List, Dict, Any, Optional, Tuple\n",
        "from pdf2image import convert_from_path\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import io\n",
        "import fitz  # PyMuPDF\n",
        "from openai import OpenAI\n",
        "from datetime import datetime\n",
        "\n",
        "# Import LayoutParser (with fallback if not available)\n",
        "try:\n",
        "    import layoutparser as lp\n",
        "    LAYOUTPARSER_AVAILABLE = True\n",
        "    print(\"âœ… LayoutParser loaded\")\n",
        "except ImportError:\n",
        "    LAYOUTPARSER_AVAILABLE = False\n",
        "    print(\"âš ï¸ LayoutParser not available - will use PyMuPDF only\")\n",
        "\n",
        "\n",
        "class ImageExtractor:\n",
        "    \"\"\"\n",
        "    Extracts images, charts, and diagrams from PDFs using hybrid detection.\n",
        "    \n",
        "    Pipeline:\n",
        "    1. PyMuPDF: Extract embedded images (photos, scans) - exact boundaries\n",
        "    2. LayoutParser: Detect figure regions (vector charts, infographics) - ML detection\n",
        "    3. Combine: Merge both sources, deduplicate overlapping regions\n",
        "    4. GPT-4o: Describe each extracted image (NOT full pages - cost efficient)\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, output_dir: str = \"image_output\", api_key: Optional[str] = None,\n",
        "                 use_layoutparser: bool = True, generate_descriptions: bool = True):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            output_dir: Directory to save extracted images\n",
        "            api_key: OpenAI API key (uses env var if not provided)\n",
        "            use_layoutparser: Whether to use LayoutParser for figure detection\n",
        "            generate_descriptions: Whether to generate LLM descriptions (costs money)\n",
        "        \"\"\"\n",
        "        self.output_dir = output_dir\n",
        "        self.images_dir = os.path.join(output_dir, \"images\")\n",
        "        self.use_layoutparser = use_layoutparser and LAYOUTPARSER_AVAILABLE\n",
        "        self.generate_descriptions = generate_descriptions\n",
        "        \n",
        "        # Create directories\n",
        "        os.makedirs(self.output_dir, exist_ok=True)\n",
        "        os.makedirs(self.images_dir, exist_ok=True)\n",
        "        \n",
        "        # Initialize OpenAI client (only if generating descriptions)\n",
        "        self.client = None\n",
        "        if generate_descriptions:\n",
        "            api_key = api_key or os.getenv(\"OPENAI_API_KEY\")\n",
        "            if api_key:\n",
        "                self.client = OpenAI(api_key=api_key)\n",
        "            else:\n",
        "                print(\"âš ï¸ No API key - descriptions will be skipped\")\n",
        "                self.generate_descriptions = False\n",
        "        \n",
        "        # Initialize LayoutParser model\n",
        "        self.lp_model = None\n",
        "        if self.use_layoutparser:\n",
        "            try:\n",
        "                # PubLayNet model - detects Text, Title, List, Table, Figure\n",
        "                self.lp_model = lp.Detectron2LayoutModel(\n",
        "                    'lp://PubLayNet/faster_rcnn_R_50_FPN_3x/config',\n",
        "                    extra_config=[\"MODEL.ROI_HEADS.SCORE_THRESH_TEST\", 0.5],\n",
        "                    label_map={0: \"Text\", 1: \"Title\", 2: \"List\", 3: \"Table\", 4: \"Figure\"}\n",
        "                )\n",
        "                print(\"âœ… LayoutParser model loaded\")\n",
        "            except Exception as e:\n",
        "                print(f\"âš ï¸ Could not load LayoutParser model: {e}\")\n",
        "                self.use_layoutparser = False\n",
        "        \n",
        "        # Counter for image IDs\n",
        "        self.image_counter = 0\n",
        "    \n",
        "    def extract(self, pdf_path: str) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Main entry point - extract all images from a PDF.\n",
        "        \n",
        "        Returns:\n",
        "            Dictionary with metadata and list of extracted images\n",
        "        \"\"\"\n",
        "        print(f\"ðŸ“„ Processing: {pdf_path}\")\n",
        "        \n",
        "        all_images = []\n",
        "        \n",
        "        # 1. Extract embedded images using PyMuPDF\n",
        "        print(\"\\nðŸ” Step 1: Extracting embedded images (PyMuPDF)...\")\n",
        "        embedded_images = self._extract_embedded_images(pdf_path)\n",
        "        print(f\"   Found {len(embedded_images)} embedded images\")\n",
        "        all_images.extend(embedded_images)\n",
        "        \n",
        "        # 2. Detect figure regions using LayoutParser\n",
        "        if self.use_layoutparser:\n",
        "            print(\"\\nðŸ” Step 2: Detecting figure regions (LayoutParser)...\")\n",
        "            figure_regions = self._detect_figure_regions(pdf_path)\n",
        "            print(f\"   Found {len(figure_regions)} figure regions\")\n",
        "            \n",
        "            # Deduplicate - remove figures that overlap with embedded images\n",
        "            unique_figures = self._deduplicate_regions(figure_regions, embedded_images)\n",
        "            print(f\"   After deduplication: {len(unique_figures)} unique figures\")\n",
        "            all_images.extend(unique_figures)\n",
        "        else:\n",
        "            print(\"\\nâ­ï¸ Step 2: Skipping LayoutParser (not available)\")\n",
        "        \n",
        "        # 3. Generate descriptions for each image\n",
        "        if self.generate_descriptions and self.client:\n",
        "            print(f\"\\nðŸ¤– Step 3: Generating descriptions for {len(all_images)} images...\")\n",
        "            for i, img_data in enumerate(all_images):\n",
        "                print(f\"   Describing image {i+1}/{len(all_images)}...\")\n",
        "                if img_data.get(\"file_path\") and os.path.exists(img_data[\"file_path\"]):\n",
        "                    description = self._describe_image(img_data[\"file_path\"])\n",
        "                    img_data[\"description\"] = description\n",
        "        else:\n",
        "            print(\"\\nâ­ï¸ Step 3: Skipping descriptions (disabled or no API key)\")\n",
        "        \n",
        "        # 4. Get page count\n",
        "        doc = fitz.open(pdf_path)\n",
        "        page_count = len(doc)\n",
        "        doc.close()\n",
        "        \n",
        "        # 5. Build result\n",
        "        result = {\n",
        "            \"metadata\": {\n",
        "                \"source_file\": os.path.basename(pdf_path),\n",
        "                \"page_count\": page_count,\n",
        "                \"images_found\": len(all_images),\n",
        "                \"extraction_timestamp\": datetime.now().isoformat(),\n",
        "                \"methods_used\": {\n",
        "                    \"pymupdf\": True,\n",
        "                    \"layoutparser\": self.use_layoutparser,\n",
        "                    \"descriptions\": self.generate_descriptions\n",
        "                }\n",
        "            },\n",
        "            \"images\": all_images\n",
        "        }\n",
        "        \n",
        "        print(f\"\\nâœ… Extraction complete! Found {len(all_images)} images across {page_count} pages.\")\n",
        "        return result\n",
        "    \n",
        "    def _extract_embedded_images(self, pdf_path: str) -> List[Dict[str, Any]]:\n",
        "        \"\"\"\n",
        "        Extract embedded images from PDF using PyMuPDF.\n",
        "        These are actual image files (JPG/PNG) stored inside the PDF.\n",
        "        \"\"\"\n",
        "        extracted = []\n",
        "        doc = fitz.open(pdf_path)\n",
        "        \n",
        "        for page_num in range(len(doc)):\n",
        "            page = doc[page_num]\n",
        "            image_list = page.get_images(full=True)\n",
        "            \n",
        "            for img_index, img_info in enumerate(image_list):\n",
        "                xref = img_info[0]  # Image reference number\n",
        "                \n",
        "                try:\n",
        "                    # Extract the image\n",
        "                    base_image = doc.extract_image(xref)\n",
        "                    image_bytes = base_image[\"image\"]\n",
        "                    image_ext = base_image[\"ext\"]\n",
        "                    \n",
        "                    # Get image position on page\n",
        "                    img_rect = page.get_image_rects(xref)\n",
        "                    bbox = None\n",
        "                    if img_rect:\n",
        "                        rect = img_rect[0]  # First occurrence\n",
        "                        page_rect = page.rect\n",
        "                        # Normalize to 0-1 range\n",
        "                        bbox = [\n",
        "                            rect.x0 / page_rect.width,\n",
        "                            rect.y0 / page_rect.height,\n",
        "                            rect.x1 / page_rect.width,\n",
        "                            rect.y1 / page_rect.height\n",
        "                        ]\n",
        "                    \n",
        "                    # Save image\n",
        "                    self.image_counter += 1\n",
        "                    image_id = f\"img_{self.image_counter:03d}\"\n",
        "                    filename = f\"page{page_num + 1}_{image_id}.{image_ext}\"\n",
        "                    save_path = os.path.join(self.images_dir, filename)\n",
        "                    \n",
        "                    with open(save_path, \"wb\") as f:\n",
        "                        f.write(image_bytes)\n",
        "                    \n",
        "                    extracted.append({\n",
        "                        \"id\": image_id,\n",
        "                        \"page\": page_num + 1,\n",
        "                        \"type\": \"embedded\",\n",
        "                        \"source\": \"pymupdf\",\n",
        "                        \"bbox\": bbox,\n",
        "                        \"file_path\": save_path,\n",
        "                        \"description\": \"\"\n",
        "                    })\n",
        "                    \n",
        "                except Exception as e:\n",
        "                    print(f\"   âš ï¸ Error extracting image {xref} on page {page_num + 1}: {e}\")\n",
        "        \n",
        "        doc.close()\n",
        "        return extracted\n",
        "    \n",
        "    def _detect_figure_regions(self, pdf_path: str) -> List[Dict[str, Any]]:\n",
        "        \"\"\"\n",
        "        Detect figure regions using LayoutParser.\n",
        "        Catches vector graphics, charts, and diagrams that aren't embedded images.\n",
        "        \"\"\"\n",
        "        if not self.lp_model:\n",
        "            return []\n",
        "        \n",
        "        detected = []\n",
        "        \n",
        "        # Render pages as images for LayoutParser\n",
        "        page_images = convert_from_path(pdf_path, dpi=150)\n",
        "        \n",
        "        for page_num, page_image in enumerate(page_images):\n",
        "            # Convert PIL to numpy array for LayoutParser\n",
        "            page_array = np.array(page_image)\n",
        "            \n",
        "            # Detect layout\n",
        "            layout = self.lp_model.detect(page_array)\n",
        "            \n",
        "            # Filter for Figure blocks only\n",
        "            figures = [block for block in layout if block.type == \"Figure\"]\n",
        "            \n",
        "            for fig in figures:\n",
        "                # Get bounding box (normalized)\n",
        "                width, height = page_image.size\n",
        "                bbox = [\n",
        "                    fig.block.x_1 / width,\n",
        "                    fig.block.y_1 / height,\n",
        "                    fig.block.x_2 / width,\n",
        "                    fig.block.y_2 / height\n",
        "                ]\n",
        "                \n",
        "                # Crop and save\n",
        "                self.image_counter += 1\n",
        "                image_id = f\"img_{self.image_counter:03d}\"\n",
        "                \n",
        "                # Crop the figure region\n",
        "                crop_box = (\n",
        "                    int(fig.block.x_1),\n",
        "                    int(fig.block.y_1),\n",
        "                    int(fig.block.x_2),\n",
        "                    int(fig.block.y_2)\n",
        "                )\n",
        "                cropped = page_image.crop(crop_box)\n",
        "                \n",
        "                filename = f\"page{page_num + 1}_{image_id}.png\"\n",
        "                save_path = os.path.join(self.images_dir, filename)\n",
        "                cropped.save(save_path, format='PNG')\n",
        "                \n",
        "                detected.append({\n",
        "                    \"id\": image_id,\n",
        "                    \"page\": page_num + 1,\n",
        "                    \"type\": \"figure\",\n",
        "                    \"source\": \"layoutparser\",\n",
        "                    \"bbox\": bbox,\n",
        "                    \"file_path\": save_path,\n",
        "                    \"description\": \"\"\n",
        "                })\n",
        "        \n",
        "        return detected\n",
        "    \n",
        "    def _deduplicate_regions(self, figures: List[Dict], embedded: List[Dict]) -> List[Dict]:\n",
        "        \"\"\"\n",
        "        Remove figure regions that significantly overlap with embedded images.\n",
        "        This prevents duplicate extraction of the same visual.\n",
        "        \"\"\"\n",
        "        unique = []\n",
        "        \n",
        "        for fig in figures:\n",
        "            fig_bbox = fig.get(\"bbox\")\n",
        "            fig_page = fig.get(\"page\")\n",
        "            \n",
        "            if not fig_bbox:\n",
        "                unique.append(fig)\n",
        "                continue\n",
        "            \n",
        "            # Check overlap with embedded images on same page\n",
        "            is_duplicate = False\n",
        "            for emb in embedded:\n",
        "                if emb.get(\"page\") != fig_page:\n",
        "                    continue\n",
        "                \n",
        "                emb_bbox = emb.get(\"bbox\")\n",
        "                if not emb_bbox:\n",
        "                    continue\n",
        "                \n",
        "                # Calculate IoU (Intersection over Union)\n",
        "                iou = self._calculate_iou(fig_bbox, emb_bbox)\n",
        "                if iou > 0.5:  # More than 50% overlap = duplicate\n",
        "                    is_duplicate = True\n",
        "                    break\n",
        "            \n",
        "            if not is_duplicate:\n",
        "                unique.append(fig)\n",
        "        \n",
        "        return unique\n",
        "    \n",
        "    def _calculate_iou(self, box1: List[float], box2: List[float]) -> float:\n",
        "        \"\"\"Calculate Intersection over Union of two bounding boxes.\"\"\"\n",
        "        x1 = max(box1[0], box2[0])\n",
        "        y1 = max(box1[1], box2[1])\n",
        "        x2 = min(box1[2], box2[2])\n",
        "        y2 = min(box1[3], box2[3])\n",
        "        \n",
        "        if x2 <= x1 or y2 <= y1:\n",
        "            return 0.0\n",
        "        \n",
        "        intersection = (x2 - x1) * (y2 - y1)\n",
        "        area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
        "        area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
        "        union = area1 + area2 - intersection\n",
        "        \n",
        "        return intersection / union if union > 0 else 0.0\n",
        "    \n",
        "    def _describe_image(self, image_path: str) -> str:\n",
        "        \"\"\"\n",
        "        Send a single extracted image to GPT-4o for description.\n",
        "        Only the image goes to the LLM - NOT the full page.\n",
        "        \"\"\"\n",
        "        if not self.client:\n",
        "            return \"\"\n",
        "        \n",
        "        try:\n",
        "            # Read and encode image\n",
        "            with open(image_path, \"rb\") as f:\n",
        "                image_bytes = f.read()\n",
        "            base64_image = base64.b64encode(image_bytes).decode('utf-8')\n",
        "            \n",
        "            # Simple prompt for description only\n",
        "            prompt = \"\"\"Describe this image in 1-2 sentences. Focus on:\n",
        "- What type of visual it is (chart, diagram, photo, etc.)\n",
        "- The key information or data it shows\n",
        "- Any labels or important text visible\n",
        "\n",
        "Be concise and factual.\"\"\"\n",
        "\n",
        "            response = self.client.chat.completions.create(\n",
        "                model=\"gpt-4o\",\n",
        "                messages=[\n",
        "                    {\n",
        "                        \"role\": \"user\",\n",
        "                        \"content\": [\n",
        "                            {\"type\": \"text\", \"text\": prompt},\n",
        "                            {\n",
        "                                \"type\": \"image_url\",\n",
        "                                \"image_url\": {\n",
        "                                    \"url\": f\"data:image/png;base64,{base64_image}\",\n",
        "                                    \"detail\": \"low\"  # Lower cost for descriptions\n",
        "                                }\n",
        "                            }\n",
        "                        ]\n",
        "                    }\n",
        "                ],\n",
        "                max_tokens=150,\n",
        "                temperature=0.2\n",
        "            )\n",
        "            \n",
        "            return response.choices[0].message.content.strip()\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"   âš ï¸ Error describing image: {e}\")\n",
        "            return \"\"\n",
        "\n",
        "\n",
        "print(\"âœ… ImageExtractor class defined (PyMuPDF + LayoutParser + GPT-4o)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Run Extraction\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize extractor and run\n",
        "# Options:\n",
        "#   use_layoutparser=True  - Detect figure regions (vector charts, infographics)\n",
        "#   generate_descriptions=True - Generate GPT-4o descriptions (costs money)\n",
        "\n",
        "extractor = ImageExtractor(\n",
        "    output_dir=OUTPUT_DIR,\n",
        "    use_layoutparser=True,       # Set to False to use only PyMuPDF\n",
        "    generate_descriptions=True   # Set to False to skip LLM descriptions\n",
        ")\n",
        "result = extractor.extract(pdf_filename)\n",
        "\n",
        "# Preview result summary\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"EXTRACTION SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Source: {result['metadata']['source_file']}\")\n",
        "print(f\"Pages: {result['metadata']['page_count']}\")\n",
        "print(f\"Images Found: {result['metadata']['images_found']}\")\n",
        "print(f\"Methods: PyMuPDF={result['metadata']['methods_used']['pymupdf']}, \"\n",
        "      f\"LayoutParser={result['metadata']['methods_used']['layoutparser']}, \"\n",
        "      f\"Descriptions={result['metadata']['methods_used']['descriptions']}\")\n",
        "print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Preview Extracted Images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import display, Image as IPImage\n",
        "\n",
        "if result[\"images\"]:\n",
        "    print(f\"Showing {len(result['images'])} extracted images:\\n\")\n",
        "    \n",
        "    for img_data in result[\"images\"]:\n",
        "        print(f\"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\")\n",
        "        source_icon = \"ðŸ“¦\" if img_data.get('source') == 'pymupdf' else \"ðŸ”\"\n",
        "        print(f\"{source_icon} {img_data['id']} | Page {img_data['page']} | Type: {img_data['type']} | Source: {img_data.get('source', 'unknown')}\")\n",
        "        if img_data.get('description'):\n",
        "            print(f\"ðŸ“ {img_data['description']}\")\n",
        "        print(f\"ðŸ“ {img_data['file_path']}\")\n",
        "        \n",
        "        # Display the image\n",
        "        if img_data.get('file_path') and os.path.exists(img_data['file_path']):\n",
        "            display(IPImage(filename=img_data['file_path'], width=400))\n",
        "        print()\n",
        "else:\n",
        "    print(\"No images were detected in this PDF.\")\n",
        "    print(\"\\nPossible reasons:\")\n",
        "    print(\"  - PDF has no embedded images (try enabling LayoutParser)\")\n",
        "    print(\"  - Images are vector graphics (LayoutParser may detect these)\")\n",
        "    print(\"  - PDF is scanned text only\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Save JSON Output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save JSON output\n",
        "output_json_path = os.path.join(OUTPUT_DIR, \"image_extractions.json\")\n",
        "\n",
        "with open(output_json_path, \"w\") as f:\n",
        "    json.dump(result, f, indent=2)\n",
        "\n",
        "print(f\"âœ… JSON saved to: {output_json_path}\")\n",
        "\n",
        "# Display JSON content\n",
        "print(\"\\nðŸ“„ JSON Content Preview:\")\n",
        "print(\"-\" * 50)\n",
        "print(json.dumps(result, indent=2)[:2000])\n",
        "if len(json.dumps(result, indent=2)) > 2000:\n",
        "    print(\"\\n... (truncated)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Download Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download JSON\n",
        "files.download(output_json_path)\n",
        "\n",
        "# Zip and download images if any were extracted\n",
        "if result[\"images\"]:\n",
        "    import shutil\n",
        "    zip_path = os.path.join(OUTPUT_DIR, \"extracted_images\")\n",
        "    shutil.make_archive(zip_path, 'zip', extractor.images_dir)\n",
        "    print(f\"âœ… Images zipped to: {zip_path}.zip\")\n",
        "    files.download(f\"{zip_path}.zip\")\n",
        "else:\n",
        "    print(\"No images to download.\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üñºÔ∏è Image Extraction Pipeline\n",
    "\n",
    "This notebook extracts **images and figures** from PDFs using a two-tier approach:\n",
    "\n",
    "| Tier | Tool | What It Detects |\n",
    "|------|------|------------------|\n",
    "| **1** | PyMuPDF | Embedded raster images (JPG/PNG stored in PDF) |\n",
    "| **2** | PaddleOCR PP-Structure | Vector figures (bar charts, diagrams, flowcharts) |\n",
    "\n",
    "## How It Works\n",
    "\n",
    "1. **PyMuPDF** extracts embedded images with exact bounding boxes\n",
    "2. **PaddleOCR PP-Structure** detects \"Figure\" regions via ML-based layout detection\n",
    "3. **Deduplication** removes overlapping detections (IoU > 0.5)\n",
    "4. **GPT-4o Vision** generates descriptions for each unique image\n",
    "\n",
    "> **Note:** Text and tables are handled separately by `universal_parser.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Install Dependencies\n",
    "# ============================\n",
    "\n",
    "# Core packages\n",
    "%pip install -q pymupdf pdf2image openai Pillow\n",
    "\n",
    "# PaddleOCR for vector figure detection (PP-Structure)\n",
    "%pip install -q paddlepaddle paddleocr\n",
    "\n",
    "# Install Poppler (required by pdf2image) - Colab only\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    subprocess.run(['apt-get', 'update', '-qq'], check=True)\n",
    "    subprocess.run(['apt-get', 'install', '-y', '-qq', 'poppler-utils'], check=True)\n",
    "    print(\"‚úÖ Poppler installed (Colab)\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Not in Colab - ensure poppler-utils is installed locally\")\n",
    "    print(\"   macOS: brew install poppler\")\n",
    "    print(\"   Ubuntu: sudo apt-get install poppler-utils\")\n",
    "\n",
    "print(\"\\n‚úÖ All dependencies installed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Configuration\n",
    "# =====================\n",
    "\n",
    "import os\n",
    "\n",
    "# ============================================\n",
    "# üîë SET YOUR OPENAI API KEY HERE\n",
    "# ============================================\n",
    "OPENAI_API_KEY = \"\"  # Paste your key or leave empty to use environment variable\n",
    "\n",
    "# Output directory for extracted images\n",
    "OUTPUT_DIR = \"image_output\"\n",
    "\n",
    "# Options\n",
    "GENERATE_DESCRIPTIONS = True  # Set False to skip LLM costs during testing\n",
    "\n",
    "# ============================================\n",
    "# Apply configuration\n",
    "# ============================================\n",
    "if OPENAI_API_KEY:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "    print(\"‚úÖ API key set from notebook\")\n",
    "elif os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    print(\"‚úÖ API key found in environment\")\n",
    "else:\n",
    "    if GENERATE_DESCRIPTIONS:\n",
    "        print(\"‚ö†Ô∏è Warning: No API key set! Descriptions will fail.\")\n",
    "        print(\"   Set OPENAI_API_KEY above or in environment.\")\n",
    "    else:\n",
    "        print(\"‚ÑπÔ∏è No API key (descriptions disabled anyway)\")\n",
    "\n",
    "print(f\"\\nüìÅ Output directory: {OUTPUT_DIR}\")\n",
    "print(f\"üìù Generate descriptions: {GENERATE_DESCRIPTIONS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Upload PDF\n",
    "# ==================\n",
    "\n",
    "import os\n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "    from google.colab import files\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"üì§ Upload your PDF file:\")\n",
    "    uploaded = files.upload()\n",
    "    PDF_PATH = list(uploaded.keys())[0]\n",
    "    print(f\"\\n‚úÖ Uploaded: {PDF_PATH}\")\n",
    "else:\n",
    "    # Local development - set path manually\n",
    "    PDF_PATH = \"sample_pdfs/your_document.pdf\"  # Change this path\n",
    "    \n",
    "    # Or use file picker\n",
    "    sample_dir = \"sample_pdfs\"\n",
    "    if os.path.exists(sample_dir):\n",
    "        pdfs = [f for f in os.listdir(sample_dir) if f.endswith('.pdf')]\n",
    "        if pdfs:\n",
    "            print(\"üìÑ Available PDFs in sample_pdfs/:\")\n",
    "            for i, pdf in enumerate(pdfs):\n",
    "                print(f\"   {i+1}. {pdf}\")\n",
    "            PDF_PATH = os.path.join(sample_dir, pdfs[0])\n",
    "            print(f\"\\n‚úÖ Using: {PDF_PATH}\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è No PDFs found in sample_pdfs/\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Directory not found: {sample_dir}\")\n",
    "        print(f\"   Set PDF_PATH manually above\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: ImageExtractor Class\n",
    "# ============================\n",
    "\n",
    "import os\n",
    "import json\n",
    "import base64\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "from pathlib import Path\n",
    "\n",
    "import fitz  # PyMuPDF\n",
    "from PIL import Image\n",
    "from pdf2image import convert_from_path\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "class ImageExtractor:\n",
    "    \"\"\"\n",
    "    Extracts images from PDFs using PyMuPDF + PaddleOCR PP-Structure.\n",
    "    Deduplicates overlapping detections and generates GPT-4o descriptions.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        output_dir: str = \"image_output\",\n",
    "        api_key: Optional[str] = None,\n",
    "        generate_descriptions: bool = True\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the ImageExtractor.\n",
    "        \n",
    "        Args:\n",
    "            output_dir: Directory to save extracted images\n",
    "            api_key: OpenAI API key (uses env var if not provided)\n",
    "            generate_descriptions: Whether to generate GPT-4o descriptions\n",
    "        \"\"\"\n",
    "        self.output_dir = Path(output_dir)\n",
    "        self.images_dir = self.output_dir / \"images\"\n",
    "        self.generate_descriptions = generate_descriptions\n",
    "        \n",
    "        # Create output directories\n",
    "        self.output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        self.images_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Setup OpenAI client\n",
    "        if generate_descriptions:\n",
    "            api_key = api_key or os.environ.get(\"OPENAI_API_KEY\")\n",
    "            if not api_key:\n",
    "                raise ValueError(\"OpenAI API key required for descriptions\")\n",
    "            self.client = OpenAI(api_key=api_key)\n",
    "        else:\n",
    "            self.client = None\n",
    "        \n",
    "        # Lazy load PaddleOCR model\n",
    "        self._layout_engine = None\n",
    "        self._paddle_loaded = False\n",
    "    \n",
    "    def _load_paddle_model(self):\n",
    "        \"\"\"Load PaddleOCR PP-Structure model.\"\"\"\n",
    "        if self._paddle_loaded:\n",
    "            return\n",
    "        \n",
    "        print(\"üîÑ Loading PaddleOCR PP-Structure model...\")\n",
    "        from paddleocr import PPStructure\n",
    "        \n",
    "        self._layout_engine = PPStructure(\n",
    "            show_log=False,\n",
    "            layout=True,\n",
    "            table=False,\n",
    "            ocr=False\n",
    "        )\n",
    "        self._paddle_loaded = True\n",
    "        print(\"‚úÖ PaddleOCR model loaded\")\n",
    "    \n",
    "    def extract(self, pdf_path: str) -> Dict:\n",
    "        \"\"\"\n",
    "        Main extraction pipeline.\n",
    "        \n",
    "        Args:\n",
    "            pdf_path: Path to the PDF file\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with metadata and extracted images\n",
    "        \"\"\"\n",
    "        pdf_path = Path(pdf_path)\n",
    "        if not pdf_path.exists():\n",
    "            raise FileNotFoundError(f\"PDF not found: {pdf_path}\")\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"üìÑ Processing: {pdf_path.name}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # Get page count\n",
    "        doc = fitz.open(pdf_path)\n",
    "        page_count = len(doc)\n",
    "        doc.close()\n",
    "        print(f\"üìë Pages: {page_count}\")\n",
    "        \n",
    "        # Step 1: Extract embedded images (PyMuPDF)\n",
    "        print(\"\\nüîç Step 1: Extracting embedded images (PyMuPDF)...\")\n",
    "        pymupdf_images = self._extract_embedded_images(pdf_path)\n",
    "        print(f\"   Found: {len(pymupdf_images)} embedded images\")\n",
    "        \n",
    "        # Step 2: Detect figure regions (PaddleOCR)\n",
    "        print(\"\\nüîç Step 2: Detecting figure regions (PaddleOCR)...\")\n",
    "        paddle_figures = self._detect_figure_regions(pdf_path)\n",
    "        print(f\"   Found: {len(paddle_figures)} figure regions\")\n",
    "        \n",
    "        # Step 3: Deduplicate\n",
    "        print(\"\\nüîç Step 3: Deduplicating overlapping detections...\")\n",
    "        unique_paddle = self._deduplicate(paddle_figures, pymupdf_images)\n",
    "        duplicates_removed = len(paddle_figures) - len(unique_paddle)\n",
    "        print(f\"   Duplicates removed: {duplicates_removed}\")\n",
    "        print(f\"   Unique PaddleOCR figures: {len(unique_paddle)}\")\n",
    "        \n",
    "        # Combine all unique images\n",
    "        all_images = pymupdf_images + unique_paddle\n",
    "        print(f\"\\nüìä Total unique images: {len(all_images)}\")\n",
    "        \n",
    "        # Step 4: Generate descriptions\n",
    "        if self.generate_descriptions and all_images:\n",
    "            print(\"\\nüîç Step 4: Generating GPT-4o descriptions...\")\n",
    "            for i, img in enumerate(all_images):\n",
    "                print(f\"   [{i+1}/{len(all_images)}] {img['id']}...\", end=\" \")\n",
    "                try:\n",
    "                    description = self._describe_image(img['file_path'])\n",
    "                    img['description'] = description\n",
    "                    print(\"‚úÖ\")\n",
    "                except Exception as e:\n",
    "                    img['description'] = f\"Error: {str(e)}\"\n",
    "                    print(f\"‚ùå {e}\")\n",
    "        else:\n",
    "            for img in all_images:\n",
    "                img['description'] = None\n",
    "            if not self.generate_descriptions:\n",
    "                print(\"\\n‚è≠Ô∏è Step 4: Skipped (descriptions disabled)\")\n",
    "        \n",
    "        # Build result\n",
    "        result = {\n",
    "            \"metadata\": {\n",
    "                \"source_file\": pdf_path.name,\n",
    "                \"page_count\": page_count,\n",
    "                \"images_found\": len(all_images),\n",
    "                \"extraction_timestamp\": datetime.now().isoformat(),\n",
    "                \"methods_used\": {\n",
    "                    \"pymupdf\": True,\n",
    "                    \"paddleocr\": True,\n",
    "                    \"descriptions\": self.generate_descriptions\n",
    "                },\n",
    "                \"stats\": {\n",
    "                    \"pymupdf_images\": len(pymupdf_images),\n",
    "                    \"paddleocr_figures\": len(paddle_figures),\n",
    "                    \"duplicates_removed\": duplicates_removed,\n",
    "                    \"unique_images\": len(all_images)\n",
    "                }\n",
    "            },\n",
    "            \"images\": all_images\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"‚úÖ Extraction complete!\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def _extract_embedded_images(self, pdf_path: Path) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Extract embedded raster images using PyMuPDF.\n",
    "        \n",
    "        Returns:\n",
    "            List of image dictionaries with id, page, type, source, bbox, file_path\n",
    "        \"\"\"\n",
    "        images = []\n",
    "        doc = fitz.open(pdf_path)\n",
    "        \n",
    "        for page_num in range(len(doc)):\n",
    "            page = doc[page_num]\n",
    "            page_rect = page.rect\n",
    "            page_width = page_rect.width\n",
    "            page_height = page_rect.height\n",
    "            \n",
    "            # Get all images on this page\n",
    "            image_list = page.get_images(full=True)\n",
    "            \n",
    "            for img_idx, img_info in enumerate(image_list):\n",
    "                xref = img_info[0]\n",
    "                \n",
    "                try:\n",
    "                    # Get image rectangle(s)\n",
    "                    rects = page.get_image_rects(xref)\n",
    "                    if not rects:\n",
    "                        continue\n",
    "                    \n",
    "                    # Use the first rectangle\n",
    "                    rect = rects[0]\n",
    "                    \n",
    "                    # Normalize bounding box (0-1)\n",
    "                    bbox = [\n",
    "                        rect.x0 / page_width,\n",
    "                        rect.y0 / page_height,\n",
    "                        rect.x1 / page_width,\n",
    "                        rect.y1 / page_height\n",
    "                    ]\n",
    "                    \n",
    "                    # Skip tiny images (likely decorative)\n",
    "                    area = (bbox[2] - bbox[0]) * (bbox[3] - bbox[1])\n",
    "                    if area < 0.01:  # Less than 1% of page\n",
    "                        continue\n",
    "                    \n",
    "                    # Extract image data\n",
    "                    base_image = doc.extract_image(xref)\n",
    "                    image_bytes = base_image[\"image\"]\n",
    "                    image_ext = base_image[\"ext\"]\n",
    "                    \n",
    "                    # Generate ID and save\n",
    "                    img_id = f\"img_{page_num+1:03d}_{img_idx+1:02d}\"\n",
    "                    file_name = f\"page{page_num+1}_{img_id}.{image_ext}\"\n",
    "                    file_path = self.images_dir / file_name\n",
    "                    \n",
    "                    with open(file_path, \"wb\") as f:\n",
    "                        f.write(image_bytes)\n",
    "                    \n",
    "                    images.append({\n",
    "                        \"id\": img_id,\n",
    "                        \"page\": page_num + 1,\n",
    "                        \"type\": \"embedded\",\n",
    "                        \"source\": \"pymupdf\",\n",
    "                        \"bbox\": bbox,\n",
    "                        \"file_path\": str(file_path)\n",
    "                    })\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"      ‚ö†Ô∏è Page {page_num+1}, image {img_idx}: {e}\")\n",
    "                    continue\n",
    "        \n",
    "        doc.close()\n",
    "        return images\n",
    "    \n",
    "    def _detect_figure_regions(self, pdf_path: Path) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Detect figure regions using PaddleOCR PP-Structure.\n",
    "        \n",
    "        Returns:\n",
    "            List of figure dictionaries with id, page, type, source, bbox, file_path\n",
    "        \"\"\"\n",
    "        self._load_paddle_model()\n",
    "        \n",
    "        import numpy as np\n",
    "        \n",
    "        figures = []\n",
    "        \n",
    "        # Render PDF pages as images\n",
    "        print(\"      Rendering PDF pages...\")\n",
    "        page_images = convert_from_path(pdf_path, dpi=150)\n",
    "        \n",
    "        for page_num, page_img in enumerate(page_images):\n",
    "            print(f\"      Processing page {page_num + 1}...\")\n",
    "            \n",
    "            # Convert PIL Image to numpy array\n",
    "            img_array = np.array(page_img)\n",
    "            img_width, img_height = page_img.size\n",
    "            \n",
    "            # Run layout detection\n",
    "            result = self._layout_engine(img_array)\n",
    "            \n",
    "            for idx, item in enumerate(result):\n",
    "                if item['type'] != 'figure':\n",
    "                    continue\n",
    "                \n",
    "                # Get bounding box [x1, y1, x2, y2]\n",
    "                x1, y1, x2, y2 = item['bbox']\n",
    "                \n",
    "                # Normalize to 0-1\n",
    "                bbox = [\n",
    "                    x1 / img_width,\n",
    "                    y1 / img_height,\n",
    "                    x2 / img_width,\n",
    "                    y2 / img_height\n",
    "                ]\n",
    "                \n",
    "                # Skip tiny detections\n",
    "                area = (bbox[2] - bbox[0]) * (bbox[3] - bbox[1])\n",
    "                if area < 0.01:\n",
    "                    continue\n",
    "                \n",
    "                # Crop and save\n",
    "                cropped = page_img.crop((int(x1), int(y1), int(x2), int(y2)))\n",
    "                fig_id = f\"fig_{page_num+1:03d}_{idx+1:02d}\"\n",
    "                file_path = self.images_dir / f\"page{page_num+1}_{fig_id}.png\"\n",
    "                cropped.save(file_path, \"PNG\")\n",
    "                \n",
    "                figures.append({\n",
    "                    \"id\": fig_id,\n",
    "                    \"page\": page_num + 1,\n",
    "                    \"type\": \"figure\",\n",
    "                    \"source\": \"paddleocr\",\n",
    "                    \"bbox\": bbox,\n",
    "                    \"file_path\": str(file_path)\n",
    "                })\n",
    "        \n",
    "        return figures\n",
    "    \n",
    "    def _deduplicate(self, paddle_figures: List[Dict], pymupdf_images: List[Dict]) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Remove PaddleOCR figures that overlap with PyMuPDF images.\n",
    "        Uses IoU (Intersection over Union) with threshold of 0.5.\n",
    "        \n",
    "        Args:\n",
    "            paddle_figures: List of figures from PaddleOCR\n",
    "            pymupdf_images: List of images from PyMuPDF\n",
    "            \n",
    "        Returns:\n",
    "            Deduplicated list of PaddleOCR figures\n",
    "        \"\"\"\n",
    "        if not paddle_figures or not pymupdf_images:\n",
    "            return paddle_figures\n",
    "        \n",
    "        unique_figures = []\n",
    "        \n",
    "        for paddle_fig in paddle_figures:\n",
    "            is_duplicate = False\n",
    "            \n",
    "            # Only compare with PyMuPDF images on the same page\n",
    "            same_page_images = [\n",
    "                img for img in pymupdf_images \n",
    "                if img['page'] == paddle_fig['page']\n",
    "            ]\n",
    "            \n",
    "            for pymupdf_img in same_page_images:\n",
    "                iou = self._calculate_iou(paddle_fig['bbox'], pymupdf_img['bbox'])\n",
    "                if iou > 0.5:\n",
    "                    is_duplicate = True\n",
    "                    # Clean up the duplicate file\n",
    "                    try:\n",
    "                        os.remove(paddle_fig['file_path'])\n",
    "                    except:\n",
    "                        pass\n",
    "                    break\n",
    "            \n",
    "            if not is_duplicate:\n",
    "                unique_figures.append(paddle_fig)\n",
    "        \n",
    "        return unique_figures\n",
    "    \n",
    "    @staticmethod\n",
    "    def _calculate_iou(box1: List[float], box2: List[float]) -> float:\n",
    "        \"\"\"\n",
    "        Calculate IoU between two bounding boxes.\n",
    "        Boxes are [x_min, y_min, x_max, y_max] normalized (0-1).\n",
    "        \"\"\"\n",
    "        # Calculate intersection\n",
    "        x1 = max(box1[0], box2[0])\n",
    "        y1 = max(box1[1], box2[1])\n",
    "        x2 = min(box1[2], box2[2])\n",
    "        y2 = min(box1[3], box2[3])\n",
    "        \n",
    "        # No overlap\n",
    "        if x2 <= x1 or y2 <= y1:\n",
    "            return 0.0\n",
    "        \n",
    "        intersection = (x2 - x1) * (y2 - y1)\n",
    "        \n",
    "        # Calculate union\n",
    "        area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "        area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "        union = area1 + area2 - intersection\n",
    "        \n",
    "        return intersection / union if union > 0 else 0.0\n",
    "    \n",
    "    def _describe_image(self, image_path: str) -> str:\n",
    "        \"\"\"\n",
    "        Generate description using GPT-4o Vision.\n",
    "        \n",
    "        Args:\n",
    "            image_path: Path to the image file\n",
    "            \n",
    "        Returns:\n",
    "            Text description of the image\n",
    "        \"\"\"\n",
    "        if not self.client:\n",
    "            return \"Descriptions disabled\"\n",
    "        \n",
    "        # Read and encode image\n",
    "        with open(image_path, \"rb\") as f:\n",
    "            image_bytes = f.read()\n",
    "        \n",
    "        base64_image = base64.b64encode(image_bytes).decode('utf-8')\n",
    "        \n",
    "        # Determine image type from extension\n",
    "        ext = Path(image_path).suffix.lower()\n",
    "        media_type = {\n",
    "            '.png': 'image/png',\n",
    "            '.jpg': 'image/jpeg',\n",
    "            '.jpeg': 'image/jpeg',\n",
    "            '.gif': 'image/gif',\n",
    "            '.webp': 'image/webp'\n",
    "        }.get(ext, 'image/png')\n",
    "        \n",
    "        prompt = \"\"\"Describe this image concisely. Include:\n",
    "1. What type of image it is (photo, chart, diagram, etc.)\n",
    "2. Key content and information shown\n",
    "3. Any important text, labels, or data\n",
    "\n",
    "Keep the description under 100 words.\"\"\"\n",
    "        \n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"text\", \"text\": prompt},\n",
    "                        {\n",
    "                            \"type\": \"image_url\",\n",
    "                            \"image_url\": {\n",
    "                                \"url\": f\"data:{media_type};base64,{base64_image}\"\n",
    "                            }\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            max_tokens=200,\n",
    "            temperature=0.3\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message.content.strip()\n",
    "\n",
    "\n",
    "print(\"‚úÖ ImageExtractor class loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Run Extraction\n",
    "# ======================\n",
    "\n",
    "# Initialize extractor\n",
    "extractor = ImageExtractor(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    generate_descriptions=GENERATE_DESCRIPTIONS\n",
    ")\n",
    "\n",
    "# Run extraction\n",
    "result = extractor.extract(PDF_PATH)\n",
    "\n",
    "# Show summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä EXTRACTION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Source: {result['metadata']['source_file']}\")\n",
    "print(f\"Pages: {result['metadata']['page_count']}\")\n",
    "print(f\"Total images: {result['metadata']['images_found']}\")\n",
    "print(f\"  - PyMuPDF: {result['metadata']['stats']['pymupdf_images']}\")\n",
    "print(f\"  - PaddleOCR: {result['metadata']['stats']['paddleocr_figures']}\")\n",
    "print(f\"  - Duplicates removed: {result['metadata']['stats']['duplicates_removed']}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Preview Extracted Images\n",
    "# =================================\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if result['images']:\n",
    "    # Create grid of images\n",
    "    n_images = len(result['images'])\n",
    "    cols = min(3, n_images)\n",
    "    rows = (n_images + cols - 1) // cols\n",
    "    \n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(5*cols, 5*rows))\n",
    "    \n",
    "    # Handle different cases for axes array\n",
    "    if n_images == 1:\n",
    "        axes = [[axes]]\n",
    "    elif rows == 1:\n",
    "        axes = [axes]\n",
    "    elif cols == 1:\n",
    "        axes = [[ax] for ax in axes]\n",
    "    \n",
    "    for idx, img_info in enumerate(result['images']):\n",
    "        row = idx // cols\n",
    "        col = idx % cols\n",
    "        ax = axes[row][col] if rows > 1 or cols > 1 else axes[0][0]\n",
    "        \n",
    "        # Load and display image\n",
    "        img = Image.open(img_info['file_path'])\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(f\"{img_info['id']} (p{img_info['page']})\\n{img_info['source']}\", fontsize=10)\n",
    "        ax.axis('off')\n",
    "    \n",
    "    # Hide empty subplots\n",
    "    for idx in range(n_images, rows * cols):\n",
    "        row = idx // cols\n",
    "        col = idx % cols\n",
    "        axes[row][col].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print descriptions\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üìù IMAGE DESCRIPTIONS\")\n",
    "    print(\"=\"*60)\n",
    "    for img_info in result['images']:\n",
    "        print(f\"\\n[{img_info['id']}] Page {img_info['page']} ({img_info['source']})\")\n",
    "        desc = img_info.get('description')\n",
    "        if desc:\n",
    "            print(f\"   {desc}\")\n",
    "        else:\n",
    "            print(\"   (No description)\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è No images found in this PDF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Save JSON and Download\n",
    "# ===============================\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Save JSON output\n",
    "output_path = Path(OUTPUT_DIR) / \"extraction_result.json\"\n",
    "with open(output_path, \"w\") as f:\n",
    "    json.dump(result, f, indent=2)\n",
    "\n",
    "print(f\"‚úÖ Results saved to: {output_path}\")\n",
    "\n",
    "# Pretty print JSON\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìÑ OUTPUT JSON\")\n",
    "print(\"=\"*60)\n",
    "print(json.dumps(result, indent=2))\n",
    "\n",
    "# Download in Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    from google.colab import files\n",
    "    \n",
    "    print(\"\\nüì• Downloading files...\")\n",
    "    \n",
    "    # Download JSON\n",
    "    files.download(str(output_path))\n",
    "    \n",
    "    # Create zip of images\n",
    "    import shutil\n",
    "    images_dir = Path(OUTPUT_DIR) / \"images\"\n",
    "    if images_dir.exists() and list(images_dir.iterdir()):\n",
    "        zip_path = Path(OUTPUT_DIR) / \"extracted_images\"\n",
    "        shutil.make_archive(str(zip_path), 'zip', str(images_dir))\n",
    "        files.download(str(zip_path) + \".zip\")\n",
    "        print(\"‚úÖ Downloaded: extraction_result.json, extracted_images.zip\")\n",
    "    else:\n",
    "        print(\"‚úÖ Downloaded: extraction_result.json\")\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"\\n‚ÑπÔ∏è Not in Colab - files saved locally:\")\n",
    "    print(f\"   JSON: {output_path}\")\n",
    "    images_dir = Path(OUTPUT_DIR) / \"images\"\n",
    "    if images_dir.exists():\n",
    "        image_files = list(images_dir.iterdir())\n",
    "        print(f\"   Images: {len(image_files)} files in {images_dir}/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
